{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf62f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL = 1 indicates running this notebook locally, 0 indicates running it on Kaggle\n",
    "LOCAL = 1\n",
    "\n",
    "import os\n",
    "if LOCAL != 1:\n",
    "  GITHUB_USER = \"magnusdtd\"\n",
    "  REPO_NAME = \"ENTRep\"\n",
    "  BRANCH_NAME = \"BioCLIP\"\n",
    "\n",
    "  from kaggle_secrets import UserSecretsClient\n",
    "  user_secrets = UserSecretsClient()\n",
    "  GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "\n",
    "  os.system(f\"git clone --single-branch --branch {BRANCH_NAME} https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\")\n",
    "  os.chdir(\"/kaggle/working/\")\n",
    "\n",
    "  from ENTRep.utils.file import File\n",
    "  File.make_train_path()\n",
    "else:\n",
    "  os.chdir(\"..\")\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(\"Current path:\", current_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8b618",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BioCLIP.make_submission import make_submission_cls_task, make_submission_t2i_task\n",
    "from BioCLIP.evaluator import ImageToTextEvaluator, TextToImageEvaluator\n",
    "from BioCLIP.data_preparation import DataPreparation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation = DataPreparation()\n",
    "image_to_text_df = data_preparation.preprocess_data()\n",
    "image_to_text_df = data_preparation.detect_and_translate(image_to_text_df)\n",
    "data_preparation.validate_dataframe(image_to_text_df)\n",
    "image_to_text_df['Path'] = image_to_text_df['Path'].apply(lambda x: os.path.join(\"/kaggle/working/\", x))\n",
    "image_to_text_df.head()\n",
    "queries = image_to_text_df['DescriptionEN'].to_list()\n",
    "\n",
    "text_to_image_evaluator = TextToImageEvaluator(\n",
    "    df=image_to_text_df,\n",
    "    queries=queries,\n",
    "    model_name='hf-hub:magnusdtd/bio-clip-cls-ft',\n",
    "    model_path='',\n",
    "    path_column='Path',\n",
    "    caption_column='DescriptionEN'\n",
    ")\n",
    "\n",
    "# Evaluate recall at k\n",
    "recall_at_k = text_to_image_evaluator.get_recall_at_k(k=10)\n",
    "print(f\"Recall at k: {recall_at_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15621bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_text_df = pd.read_json('Dataset/train/cls.json', orient='index')\n",
    "image_to_text_df = image_to_text_df.reset_index()\n",
    "image_to_text_df.columns = ['Path', 'Ground Truth Label']\n",
    "image_to_text_df['Path'] = image_to_text_df['Path'].apply(lambda x: os.path.join(\"/kaggle/working/Dataset/train/imgs\", x))\n",
    "image_to_text_df\n",
    "\n",
    "labels = [\n",
    "    \"nose-right\", \n",
    "    \"nose-left\" , \n",
    "    \"ear-right\" , \n",
    "    \"ear-left\"  , \n",
    "    \"vc-open\"   , \n",
    "    \"vc-closed\" , \n",
    "    \"throat\"    , \n",
    "]\n",
    "\n",
    "image_to_text_evaluator = ImageToTextEvaluator(\n",
    "    df=image_to_text_df,\n",
    "    labels=labels,\n",
    "    model_name='hf-hub:magnusdtd/bio-clip-cls-ft',\n",
    "    model_path='',\n",
    "    path_column='Path',\n",
    "    caption_column='Ground Truth Label'\n",
    ")\n",
    "\n",
    "accuracy = image_to_text_evaluator.get_accuracy()\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "precision, recall, f1_score = image_to_text_evaluator.get_f1_score()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214adf1e",
   "metadata": {},
   "source": [
    "# Make submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_cls_task(\n",
    "  model_name=\"hf-hub:magnusdtd/bio-clip-cls-ft\",\n",
    "  model_path=\"\",\n",
    "  test_file_path=\"Dataset/test/cls.csv\",\n",
    "  labels_map = {\n",
    "    \"This is an endoscopic image showing nose-right-anterior, nose-right-middle, nose-right-posterior, nose-right-inferior-turbinate, nose-right-septum.\": 0, \n",
    "    \"This is an endoscopic image showing nose-left-anterior, nose-left-middle, nose-left-posterior, nose-left-inferior-turbinate, nose-left-septum.\" : 1, \n",
    "    \"This is an endoscopic image showing ear-right-tympanic-membrane, ear-right-ear-canal, ear-right-middle-ear.\" : 2, \n",
    "    \"This is an endoscopic image showing ear-left-tympanic-membrane, ear-left-ear-canal, ear-left-middle-ear.\"  : 3, \n",
    "    \"This is an endoscopic image showing vc-open-full-view, vc-open-partial-view.\"   : 4, \n",
    "    \"This is an endoscopic image showing vc-closed-full-view, vc-closed-partial-view.\" : 5, \n",
    "    \"This is an endoscopic image showing oropharynx, laryngopharynx, tonsils, uvula, epiglottis.\"    : 6, \n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission_t2i_task(\n",
    "  model_name=\"hf-hub:magnusdtd/bio-clip-cls-ft\",\n",
    "  model_path=\"\",\n",
    "  test_file_path=\"Dataset/test/t2i.csv\",\n",
    "  image_folder_path=\"Dataset/test/imgs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0396720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
