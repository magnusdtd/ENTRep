{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL = 1 indicates running this notebook locally, 0 indicates running it on Kaggle\n",
    "LOCAL = 0\n",
    "\n",
    "import os\n",
    "if LOCAL != 1:\n",
    "  GITHUB_USER = \"magnusdtd\"\n",
    "  REPO_NAME = \"ENTRep\"\n",
    "  BRANCH_NAME = \"BioCLIP\"\n",
    "\n",
    "  from kaggle_secrets import UserSecretsClient\n",
    "  user_secrets = UserSecretsClient()\n",
    "  GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "\n",
    "  os.system(f\"git clone --single-branch --branch {BRANCH_NAME} https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\")\n",
    "  os.chdir(\"/kaggle/working/\")\n",
    "\n",
    "  from ENTRep.utils.file import File\n",
    "  File.make_train_path()\n",
    "else:\n",
    "  os.chdir(\"..\")\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(\"Current path:\", current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02141727",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"font-size:2.5em;\"><b>ENTRep Text-to-Image Retrieval</b></p>\n",
    "<p align=\"center\" style=\"font-size:2em;\">BioCLIP</p>\n",
    "<p align=\"center\" style=\"font-size:1em;\">Made by Dam Tien Dat</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c305c47",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BioCLIP.data_preparation import DataPreparation\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d563ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation = DataPreparation()\n",
    "\n",
    "df = data_preparation.preprocess_data()\n",
    "df = data_preparation.detect_and_translate(df)\n",
    "data_preparation.validate_dataframe(df)\n",
    "df['Path'] = df['Path'].apply(lambda x: os.path.join(\"/kaggle/working/\", x))\n",
    "df.to_csv('Dataset/data.csv', index_label=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d58be6c",
   "metadata": {},
   "source": [
    "Clone repo, change current directory and make new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86703b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pure_bioclip'):\n",
    "  os.system('git clone https://huggingface.co/imageomics/bioclip pure_bioclip')\n",
    "if not os.path.exists('open_clip'):\n",
    "  os.system('git clone https://github.com/mlfoundations/open_clip.git')\n",
    "if not os.path.exists('open_clip/src'):\n",
    "  raise FileNotFoundError(\"The 'open_clip/src' directory does not exist after cloning.\")\n",
    "os.chdir('open_clip/src')\n",
    "if not os.path.exists('./logs'):\n",
    "  os.makedirs('./logs', exist_ok=True)\n",
    "os.system(\"pip install -r ./../requirements-training.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275292a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node 2 -m open_clip_train.main \\\n",
    "    --batch-size 32 \\\n",
    "    --precision amp \\\n",
    "    --workers 4 \\\n",
    "    --save-frequency 3 \\\n",
    "    --dataset-type csv \\\n",
    "    --csv-separator=\",\" \\\n",
    "    --train-data \"./../../Dataset/data.csv\" \\\n",
    "    --csv-img-key Path \\\n",
    "    --csv-caption-key DescriptionEN \\\n",
    "    --warmup 1000 \\\n",
    "    --lr=5e-6 \\\n",
    "    --wd=0.1 \\\n",
    "    --epochs=5 \\\n",
    "    --model \"hf-hub:imageomics/bioclip\" \\\n",
    "    --pretrained \"./../../pure_bioclip/open_clip_pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m open_clip.push_to_hf_hub \\\n",
    "  --model convnext_large_d_320 \\\n",
    "  --pretrained logs//checkpoints/epoch_5.pt \\\n",
    "  --repo-id magnusdtd/bio-clip-ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./../..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
