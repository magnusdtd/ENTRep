{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL = 1 indicates running this notebook locally, 0 indicates running it on Kaggle\n",
    "LOCAL = 1\n",
    "\n",
    "import os\n",
    "if LOCAL != 1:\n",
    "  GITHUB_USER = \"magnusdtd\"\n",
    "  REPO_NAME = \"ENTRep\"\n",
    "  BRANCH_NAME = \"ResNetv2\"\n",
    "\n",
    "  from kaggle_secrets import UserSecretsClient\n",
    "  user_secrets = UserSecretsClient()\n",
    "  GITHUB_TOKEN = user_secrets.get_secret(\"GITHUB_TOKEN\")\n",
    "\n",
    "  !git clone --single-branch --branch {BRANCH_NAME} https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\n",
    "\n",
    "  os.chdir(\"/kaggle/working/\")\n",
    "\n",
    "  from ENTRep.utils.file import File\n",
    "  File.make_train_path()\n",
    "else:\n",
    "  os.chdir(\"..\")\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print(\"Current path:\", current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b14cf",
   "metadata": {},
   "source": [
    "<p align=\"center\" style=\"font-size:2.5em;\"><b>ENTRep EfficientNet</b></p>\n",
    "<p align=\"center\" style=\"font-size:1em;\">Made by Dam Tien Dat</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "from classification.k_fold import K_Fold\n",
    "from EfficientNet.EfficientNet import EfficientNet\n",
    "from classification.dataset import ENTRepDataset\n",
    "from classification.transform import get_transform, visualize_sample\n",
    "from classification.inference import random_inference_9_images\n",
    "from classification.evaluate import evaluate_class_model\n",
    "from classification.make_submission import make_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe380036",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('Dataset/train/cls.json', orient='index')\n",
    "df = df.reset_index()\n",
    "df.columns = ['Path', 'Classification']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature_map = {\n",
    "  \"nose-right\": 0, \n",
    "  \"nose-left\" : 1, \n",
    "  \"ear-right\" : 2, \n",
    "  \"ear-left\"  : 3, \n",
    "  \"vc-open\"   : 4, \n",
    "  \"vc-closed\" : 5, \n",
    "  \"throat\"    : 6, \n",
    "}\n",
    "class_feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82d636",
   "metadata": {},
   "source": [
    "## Visualize transformed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b27441",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ENTRepDataset(df, class_feature_map, transform=get_transform(train=True))\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "visualize_sample(data_loader, class_feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716019e",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b02bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).named_parameters():\n",
    "  print(f\" - {name}, requires grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet(\n",
    "  backbone=models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT),\n",
    "  lr = 1e-3,\n",
    "  earlyStopping_patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afde938",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = K_Fold(\n",
    "  k=5, \n",
    "  df=df, \n",
    "  model=model, \n",
    "  class_feature_map=class_feature_map,\n",
    "  epochs=100,\n",
    "  unfreeze_layers=['classifier', 'features.8', 'features.7']\n",
    ")\n",
    "kf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.show_learning_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460acd0",
   "metadata": {},
   "source": [
    "# Save Model State and Perform Inference\n",
    "In this section, we will save the trained model state and use it to perform inference on a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model_state(\"EfficientNet_B0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "saved_model = EfficientNet.load_model(\n",
    "  \"EfficientNet_B0.pth\", \n",
    "  models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5900aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_inference_9_images(saved_model, df, class_feature_map, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae39ef8",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c749b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ENTRepDataset(df, class_feature_map, transform=get_transform(train=True))\n",
    "dataLoader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_class_model(saved_model, dataLoader, class_feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349cde1",
   "metadata": {},
   "source": [
    "# Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918bf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(saved_model, 'EfficientNet_B0', device, 'Dataset/test/cls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba18986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
